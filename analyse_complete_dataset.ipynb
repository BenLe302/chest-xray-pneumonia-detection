{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü´Å Analyse Compl√®te du Dataset Chest X-Ray Pneumonia\n",
    "\n",
    "## üìä Cr√©dits et Source des Donn√©es\n",
    "\n",
    "**Dataset :** [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)\n",
    "**Source :** Kaggle\n",
    "**Cr√©ateur :** Paul Mooney\n",
    "**Auteur de l'analyse :** Dady Akrou Cyrille\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectif du Projet\n",
    "\n",
    "Ce notebook pr√©sente une analyse compl√®te du dataset de radiographies thoraciques pour la d√©tection automatique de pneumonie. L'objectif est de d√©velopper un mod√®le de deep learning capable de classifier les radiographies en deux cat√©gories :\n",
    "\n",
    "- **NORMAL** : Radiographies sans pneumonie\n",
    "- **PNEUMONIA** : Radiographies avec pneumonie\n",
    "\n",
    "## üìã Table des Mati√®res\n",
    "\n",
    "1. [Configuration et Imports](#1-configuration-et-imports)\n",
    "2. [Exploration du Dataset](#2-exploration-du-dataset)\n",
    "3. [Analyse Statistique](#3-analyse-statistique)\n",
    "4. [Visualisations Avanc√©es](#4-visualisations-avanc√©es)\n",
    "5. [Analyse des Images](#5-analyse-des-images)\n",
    "6. [Recommandations ML](#6-recommandations-ml)\n",
    "7. [Conclusions](#7-conclusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et Imports\n",
    "\n",
    "### Installation des d√©pendances\n",
    "\n",
    "Si vous ex√©cutez ce notebook pour la premi√®re fois, d√©commentez et ex√©cutez la cellule suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports et configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports standards\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Imports pour l'analyse de donn√©es\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imports pour la visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "# Imports pour le traitement d'images\n",
    "import cv2\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Configuration matplotlib pour l'affichage en fran√ßais\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3\n",
    "\n",
    "print(\"‚úÖ Configuration termin√©e avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des modules du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des modules personnalis√©s\n",
    "from config import *\n",
    "from utils import *\n",
    "\n",
    "# Affichage de l'en-t√™te du projet\n",
    "afficher_entete_projet()\n",
    "\n",
    "print(f\"üìÅ R√©pertoire de travail : {os.getcwd()}\")\n",
    "print(f\"üìä Dataset configur√© : {DATASET_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploration du Dataset\n",
    "\n",
    "### Validation de la structure du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation de la structure\n",
    "print(\"üîç Validation de la structure du dataset...\")\n",
    "\n",
    "structure_valide = valider_structure_dataset(DATASET_PATH)\n",
    "\n",
    "if structure_valide:\n",
    "    print(\"‚úÖ Structure du dataset valid√©e avec succ√®s !\")\n",
    "else:\n",
    "    print(\"‚ùå Probl√®me d√©tect√© dans la structure du dataset\")\n",
    "    print(\"Veuillez v√©rifier que le dataset est correctement organis√©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration de la structure des dossiers\n",
    "print(\"üìÇ Structure du dataset :\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    subset_path = os.path.join(DATASET_PATH, subset)\n",
    "    if os.path.exists(subset_path):\n",
    "        print(f\"\\nüìÅ {subset.upper()}/\")\n",
    "        for classe in CLASSES:\n",
    "            classe_path = os.path.join(subset_path, classe)\n",
    "            if os.path.exists(classe_path):\n",
    "                nb_images = compter_images(classe_path)\n",
    "                print(f\"  ‚îî‚îÄ‚îÄ {classe}: {nb_images:,} images\")\n",
    "            else:\n",
    "                print(f\"  ‚îî‚îÄ‚îÄ {classe}: ‚ùå Dossier manquant\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå {subset.upper()}/: Dossier manquant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Analyse Statistique\n",
    "\n",
    "### Statistiques g√©n√©rales du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtention des statistiques compl√®tes\n",
    "print(\"üìä Calcul des statistiques du dataset...\")\n",
    "\n",
    "stats = obtenir_statistiques_dataset(DATASET_PATH)\n",
    "\n",
    "# Affichage des statistiques g√©n√©rales\n",
    "print(\"\\nüî¢ STATISTIQUES G√âN√âRALES\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üìä Total d'images : {stats['total_images']:,}\")\n",
    "print(f\"üìÅ Nombre de classes : {len(CLASSES)}\")\n",
    "print(f\"üìÇ Nombre de sous-ensembles : {len(SUBSETS)}\")\n",
    "\n",
    "# Statistiques par sous-ensemble\n",
    "print(\"\\nüìÇ R√âPARTITION PAR SOUS-ENSEMBLE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    if subset in stats['par_subset']:\n",
    "        subset_stats = stats['par_subset'][subset]\n",
    "        total_subset = sum(subset_stats.values())\n",
    "        pourcentage = (total_subset / stats['total_images']) * 100\n",
    "        \n",
    "        print(f\"\\nüìÅ {subset.upper()}:\")\n",
    "        print(f\"   Total: {total_subset:,} images ({pourcentage:.1f}%)\")\n",
    "        \n",
    "        for classe in CLASSES:\n",
    "            if classe in subset_stats:\n",
    "                nb_images = subset_stats[classe]\n",
    "                pourcentage_classe = (nb_images / total_subset) * 100 if total_subset > 0 else 0\n",
    "                print(f\"   ‚îî‚îÄ‚îÄ {classe}: {nb_images:,} ({pourcentage_classe:.1f}%)\")\n",
    "            else:\n",
    "                print(f\"   ‚îî‚îÄ‚îÄ {classe}: 0 (0.0%)\")\n",
    "    else:\n",
    "        print(f\"\\n‚ùå {subset.upper()}: Aucune donn√©e trouv√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse du d√©s√©quilibre des classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des poids de classes\n",
    "print(\"‚öñÔ∏è ANALYSE DU D√âS√âQUILIBRE DES CLASSES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "poids_classes = calculer_poids_classes(stats)\n",
    "\n",
    "# Statistiques globales par classe\n",
    "total_par_classe = {}\n",
    "for classe in CLASSES:\n",
    "    total = 0\n",
    "    for subset in SUBSETS:\n",
    "        if subset in stats['par_subset'] and classe in stats['par_subset'][subset]:\n",
    "            total += stats['par_subset'][subset][classe]\n",
    "    total_par_classe[classe] = total\n",
    "\n",
    "print(\"üìä R√©partition globale par classe :\")\n",
    "for classe in CLASSES:\n",
    "    total = total_par_classe[classe]\n",
    "    pourcentage = (total / stats['total_images']) * 100\n",
    "    print(f\"   {classe}: {total:,} images ({pourcentage:.1f}%)\")\n",
    "\n",
    "# Calcul du ratio de d√©s√©quilibre\n",
    "if len(total_par_classe) == 2:\n",
    "    classes_list = list(total_par_classe.keys())\n",
    "    ratio = max(total_par_classe.values()) / min(total_par_classe.values())\n",
    "    classe_majoritaire = max(total_par_classe, key=total_par_classe.get)\n",
    "    classe_minoritaire = min(total_par_classe, key=total_par_classe.get)\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è Ratio de d√©s√©quilibre : {ratio:.2f}:1\")\n",
    "    print(f\"   Classe majoritaire : {classe_majoritaire}\")\n",
    "    print(f\"   Classe minoritaire : {classe_minoritaire}\")\n",
    "\n",
    "print(\"\\nüéØ Poids recommand√©s pour l'entra√Ænement :\")\n",
    "for classe, poids in poids_classes.items():\n",
    "    print(f\"   {classe}: {poids:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisations Avanc√©es\n",
    "\n",
    "### Graphiques de distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation des visualisations\n",
    "print(\"üìà G√©n√©ration des visualisations...\")\n",
    "\n",
    "# Pr√©paration des donn√©es pour les graphiques\n",
    "data_viz = []\n",
    "\n",
    "for subset in SUBSETS:\n",
    "    if subset in stats['par_subset']:\n",
    "        for classe, count in stats['par_subset'][subset].items():\n",
    "            data_viz.append({\n",
    "                'Sous-ensemble': subset.capitalize(),\n",
    "                'Classe': classe,\n",
    "                'Nombre': count\n",
    "            })\n",
    "\n",
    "df_viz = pd.DataFrame(data_viz)\n",
    "\n",
    "# Graphique 1: Distribution par sous-ensemble et classe\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üìä Analyse Compl√®te du Dataset Chest X-Ray Pneumonia', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Graphique en barres group√©es\n",
    "ax1 = axes[0, 0]\n",
    "df_pivot = df_viz.pivot(index='Sous-ensemble', columns='Classe', values='Nombre')\n",
    "df_pivot.plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral'])\n",
    "ax1.set_title('Distribution par Sous-ensemble et Classe')\n",
    "ax1.set_xlabel('Sous-ensemble')\n",
    "ax1.set_ylabel('Nombre d\\'images')\n",
    "ax1.legend(title='Classe')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Graphique en secteurs pour la distribution globale\n",
    "ax2 = axes[0, 1]\n",
    "total_par_classe_list = [total_par_classe[classe] for classe in CLASSES]\n",
    "colors = ['lightblue', 'lightcoral']\n",
    "wedges, texts, autotexts = ax2.pie(total_par_classe_list, labels=CLASSES, autopct='%1.1f%%', \n",
    "                                   colors=colors, startangle=90)\n",
    "ax2.set_title('R√©partition Globale des Classes')\n",
    "\n",
    "# Graphique en barres horizontales pour les sous-ensembles\n",
    "ax3 = axes[1, 0]\n",
    "subset_totals = [sum(stats['par_subset'][subset].values()) if subset in stats['par_subset'] else 0 \n",
    "                 for subset in SUBSETS]\n",
    "bars = ax3.barh(SUBSETS, subset_totals, color=['lightgreen', 'orange', 'lightpink'])\n",
    "ax3.set_title('Nombre d\\'Images par Sous-ensemble')\n",
    "ax3.set_xlabel('Nombre d\\'images')\n",
    "\n",
    "# Ajout des valeurs sur les barres\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax3.text(width + 50, bar.get_y() + bar.get_height()/2, \n",
    "             f'{int(width):,}', ha='left', va='center')\n",
    "\n",
    "# Graphique de comparaison des ratios\n",
    "ax4 = axes[1, 1]\n",
    "ratios_data = []\n",
    "for subset in SUBSETS:\n",
    "    if subset in stats['par_subset']:\n",
    "        subset_stats = stats['par_subset'][subset]\n",
    "        if len(subset_stats) == 2:\n",
    "            ratio = max(subset_stats.values()) / min(subset_stats.values())\n",
    "            ratios_data.append(ratio)\n",
    "        else:\n",
    "            ratios_data.append(0)\n",
    "    else:\n",
    "        ratios_data.append(0)\n",
    "\n",
    "bars = ax4.bar(SUBSETS, ratios_data, color=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "ax4.set_title('Ratio de D√©s√©quilibre par Sous-ensemble')\n",
    "ax4.set_ylabel('Ratio (Majoritaire:Minoritaire)')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Ajout d'une ligne de r√©f√©rence pour un ratio √©quilibr√©\n",
    "ax4.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='√âquilibre parfait')\n",
    "ax4.legend()\n",
    "\n",
    "# Ajout des valeurs sur les barres\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    if height > 0:\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, height + 0.1, \n",
    "                 f'{height:.2f}:1', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualisations g√©n√©r√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse des Images\n",
    "\n",
    "### Propri√©t√©s des images (dimensions, formats, tailles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des propri√©t√©s des images\n",
    "print(\"üñºÔ∏è Analyse des propri√©t√©s des images...\")\n",
    "print(\"‚è≥ Cette op√©ration peut prendre quelques minutes...\\n\")\n",
    "\n",
    "proprietes = analyser_proprietes_images(DATASET_PATH)\n",
    "\n",
    "print(\"üìä PROPRI√âT√âS DES IMAGES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Formats d'images\n",
    "print(\"üé® Formats d√©tect√©s :\")\n",
    "for format_img, count in proprietes['formats'].items():\n",
    "    pourcentage = (count / proprietes['total_analysees']) * 100\n",
    "    print(f\"   {format_img}: {count:,} images ({pourcentage:.1f}%)\")\n",
    "\n",
    "# Dimensions\n",
    "print(\"\\nüìê Dimensions des images :\")\n",
    "print(f\"   Largeur moyenne : {proprietes['largeur_moyenne']:.0f} pixels\")\n",
    "print(f\"   Hauteur moyenne : {proprietes['hauteur_moyenne']:.0f} pixels\")\n",
    "print(f\"   Dimension la plus fr√©quente : {proprietes['dimension_plus_frequente']}\")\n",
    "\n",
    "# Tailles de fichiers\n",
    "print(\"\\nüíæ Tailles des fichiers :\")\n",
    "print(f\"   Taille moyenne : {proprietes['taille_moyenne_mb']:.2f} MB\")\n",
    "print(f\"   Taille m√©diane : {proprietes['taille_mediane_mb']:.2f} MB\")\n",
    "print(f\"   Taille minimale : {proprietes['taille_min_mb']:.3f} MB\")\n",
    "print(f\"   Taille maximale : {proprietes['taille_max_mb']:.2f} MB\")\n",
    "\n",
    "print(f\"\\nüîç Images analys√©es : {proprietes['total_analysees']:,} / {stats['total_images']:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des propri√©t√©s des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des propri√©t√©s des images\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('üñºÔ∏è Analyse des Propri√©t√©s des Images', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Graphique 1: Distribution des largeurs\n",
    "ax1 = axes[0, 0]\n",
    "largeurs = [dim[0] for dim in proprietes['dimensions']]\n",
    "ax1.hist(largeurs, bins=30, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "ax1.set_title('Distribution des Largeurs')\n",
    "ax1.set_xlabel('Largeur (pixels)')\n",
    "ax1.set_ylabel('Fr√©quence')\n",
    "ax1.axvline(proprietes['largeur_moyenne'], color='red', linestyle='--', \n",
    "           label=f'Moyenne: {proprietes[\"largeur_moyenne\"]:.0f}px')\n",
    "ax1.legend()\n",
    "\n",
    "# Graphique 2: Distribution des hauteurs\n",
    "ax2 = axes[0, 1]\n",
    "hauteurs = [dim[1] for dim in proprietes['dimensions']]\n",
    "ax2.hist(hauteurs, bins=30, color='lightcoral', alpha=0.7, edgecolor='black')\n",
    "ax2.set_title('Distribution des Hauteurs')\n",
    "ax2.set_xlabel('Hauteur (pixels)')\n",
    "ax2.set_ylabel('Fr√©quence')\n",
    "ax2.axvline(proprietes['hauteur_moyenne'], color='red', linestyle='--', \n",
    "           label=f'Moyenne: {proprietes[\"hauteur_moyenne\"]:.0f}px')\n",
    "ax2.legend()\n",
    "\n",
    "# Graphique 3: Distribution des tailles de fichiers\n",
    "ax3 = axes[1, 0]\n",
    "tailles_mb = [taille / (1024*1024) for taille in proprietes['tailles']]\n",
    "ax3.hist(tailles_mb, bins=30, color='lightgreen', alpha=0.7, edgecolor='black')\n",
    "ax3.set_title('Distribution des Tailles de Fichiers')\n",
    "ax3.set_xlabel('Taille (MB)')\n",
    "ax3.set_ylabel('Fr√©quence')\n",
    "ax3.axvline(proprietes['taille_moyenne_mb'], color='red', linestyle='--', \n",
    "           label=f'Moyenne: {proprietes[\"taille_moyenne_mb\"]:.2f}MB')\n",
    "ax3.legend()\n",
    "\n",
    "# Graphique 4: Scatter plot largeur vs hauteur\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(largeurs, hauteurs, alpha=0.6, color='purple', s=10)\n",
    "ax4.set_title('Relation Largeur vs Hauteur')\n",
    "ax4.set_xlabel('Largeur (pixels)')\n",
    "ax4.set_ylabel('Hauteur (pixels)')\n",
    "\n",
    "# Ajout de la ligne de ratio 1:1\n",
    "max_dim = max(max(largeurs), max(hauteurs))\n",
    "ax4.plot([0, max_dim], [0, max_dim], 'r--', alpha=0.5, label='Ratio 1:1')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualisations des propri√©t√©s g√©n√©r√©es avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### √âchantillons d'images par classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage d'√©chantillons d'images\n",
    "print(\"üñºÔ∏è Affichage d'√©chantillons d'images par classe...\")\n",
    "\n",
    "def afficher_echantillons(dataset_path, nb_echantillons=3):\n",
    "    \"\"\"Affiche des √©chantillons d'images pour chaque classe\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(len(CLASSES), nb_echantillons, \n",
    "                            figsize=(nb_echantillons * 4, len(CLASSES) * 4))\n",
    "    \n",
    "    if len(CLASSES) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    fig.suptitle('üñºÔ∏è √âchantillons d\\'Images par Classe', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, classe in enumerate(CLASSES):\n",
    "        # Chercher des images dans le dossier train en priorit√©\n",
    "        classe_path = os.path.join(dataset_path, 'train', classe)\n",
    "        \n",
    "        if not os.path.exists(classe_path):\n",
    "            # Si pas de dossier train, chercher dans test\n",
    "            classe_path = os.path.join(dataset_path, 'test', classe)\n",
    "        \n",
    "        if os.path.exists(classe_path):\n",
    "            images = [f for f in os.listdir(classe_path) \n",
    "                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            # S√©lectionner des √©chantillons al√©atoires\n",
    "            echantillons = np.random.choice(images, \n",
    "                                          min(nb_echantillons, len(images)), \n",
    "                                          replace=False)\n",
    "            \n",
    "            for j, image_name in enumerate(echantillons):\n",
    "                image_path = os.path.join(classe_path, image_name)\n",
    "                \n",
    "                try:\n",
    "                    # Charger et afficher l'image\n",
    "                    img = Image.open(image_path)\n",
    "                    \n",
    "                    if len(CLASSES) == 1:\n",
    "                        ax = axes[j]\n",
    "                    else:\n",
    "                        ax = axes[i, j]\n",
    "                    \n",
    "                    ax.imshow(img, cmap='gray' if img.mode == 'L' else None)\n",
    "                    ax.set_title(f'{classe}\\n{img.size[0]}x{img.size[1]}px')\n",
    "                    ax.axis('off')\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if len(CLASSES) == 1:\n",
    "                        ax = axes[j]\n",
    "                    else:\n",
    "                        ax = axes[i, j]\n",
    "                    \n",
    "                    ax.text(0.5, 0.5, f'Erreur\\nchargement\\n{str(e)[:20]}...', \n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.axis('off')\n",
    "        else:\n",
    "            # Si le dossier n'existe pas\n",
    "            for j in range(nb_echantillons):\n",
    "                if len(CLASSES) == 1:\n",
    "                    ax = axes[j]\n",
    "                else:\n",
    "                    ax = axes[i, j]\n",
    "                \n",
    "                ax.text(0.5, 0.5, f'Dossier\\n{classe}\\nintrouvable', \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Affichage des √©chantillons\n",
    "afficher_echantillons(DATASET_PATH, nb_echantillons=4)\n",
    "\n",
    "print(\"‚úÖ √âchantillons d'images affich√©s avec succ√®s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recommandations ML\n",
    "\n",
    "### Strat√©gies recommand√©es pour ce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©ration des recommandations ML\n",
    "print(\"üéØ RECOMMANDATIONS MACHINE LEARNING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyse du d√©s√©quilibre\n",
    "ratio_desequilibre = max(total_par_classe.values()) / min(total_par_classe.values())\n",
    "\n",
    "print(\"‚öñÔ∏è GESTION DU D√âS√âQUILIBRE DES CLASSES\")\n",
    "print(f\"   Ratio actuel : {ratio_desequilibre:.2f}:1\")\n",
    "\n",
    "if ratio_desequilibre > 2.0:\n",
    "    print(\"   üö® D√âS√âQUILIBRE SIGNIFICATIF D√âTECT√â\")\n",
    "    print(\"   \n",
    "   Strat√©gies recommand√©es :\")\n",
    "    print(\"   ‚Ä¢ Utiliser les poids de classes calcul√©s\")\n",
    "    print(\"   ‚Ä¢ Appliquer des techniques de sur-√©chantillonnage (SMOTE)\")\n",
    "    print(\"   ‚Ä¢ Augmentation de donn√©es cibl√©e sur la classe minoritaire\")\n",
    "    print(\"   ‚Ä¢ Utiliser des m√©triques √©quilibr√©es (F1-score, AUC-ROC)\")\n",
    "elif ratio_desequilibre > 1.5:\n",
    "    print(\"   ‚ö†Ô∏è D√©s√©quilibre mod√©r√©\")\n",
    "    print(\"   Strat√©gies recommand√©es :\")\n",
    "    print(\"   ‚Ä¢ Utiliser les poids de classes\")\n",
    "    print(\"   ‚Ä¢ Surveiller les m√©triques par classe\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Dataset relativement √©quilibr√©\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è ARCHITECTURE DE MOD√àLE RECOMMAND√âE\")\n",
    "print(\"   Pour la classification d'images m√©dicales :\")\n",
    "print(\"   ‚Ä¢ Transfer Learning avec des mod√®les pr√©-entra√Æn√©s\")\n",
    "print(\"   ‚Ä¢ ResNet50/101 ou EfficientNet (recommand√©s pour l'imagerie m√©dicale)\")\n",
    "print(\"   ‚Ä¢ Fine-tuning des derni√®res couches\")\n",
    "print(\"   ‚Ä¢ Dropout et r√©gularisation pour √©viter le surapprentissage\")\n",
    "\n",
    "print(\"\\nüìä M√âTRIQUES D'√âVALUATION RECOMMAND√âES\")\n",
    "print(\"   Pour un contexte m√©dical :\")\n",
    "print(\"   ‚Ä¢ Sensibilit√© (Recall) - Crucial pour d√©tecter la pneumonie\")\n",
    "print(\"   ‚Ä¢ Sp√©cificit√© - Important pour √©viter les faux positifs\")\n",
    "print(\"   ‚Ä¢ F1-Score - √âquilibre entre pr√©cision et rappel\")\n",
    "print(\"   ‚Ä¢ AUC-ROC - Performance globale du mod√®le\")\n",
    "print(\"   ‚Ä¢ Matrice de confusion d√©taill√©e\")\n",
    "\n",
    "print(\"\\nüîÑ AUGMENTATION DE DONN√âES RECOMMAND√âE\")\n",
    "print(\"   Techniques adapt√©es aux radiographies :\")\n",
    "print(\"   ‚Ä¢ Rotation l√©g√®re (¬±10-15¬∞)\")\n",
    "print(\"   ‚Ä¢ Translation horizontale/verticale\")\n",
    "print(\"   ‚Ä¢ Zoom l√©ger\")\n",
    "print(\"   ‚Ä¢ Ajustement de contraste et luminosit√©\")\n",
    "print(\"   ‚Ä¢ ‚ö†Ô∏è √âviter : flip horizontal (anatomie)\")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è CONFIGURATION D'ENTRA√éNEMENT\")\n",
    "print(f\"   ‚Ä¢ Taille d'image recommand√©e : {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Batch size : {BATCH_SIZE}\")\n",
    "print(f\"   ‚Ä¢ Learning rate initial : {LEARNING_RATE}\")\n",
    "print(f\"   ‚Ä¢ Nombre d'√©poques max : {EPOCHS}\")\n",
    "print(f\"   ‚Ä¢ Early stopping patience : {PATIENCE}\")\n",
    "\n",
    "print(\"\\nüìã VALIDATION ET TEST\")\n",
    "\n",
    "# Analyse de la r√©partition train/val/test\n",
    "train_total = sum(stats['par_subset']['train'].values()) if 'train' in stats['par_subset'] else 0\n",
    "val_total = sum(stats['par_subset']['val'].values()) if 'val' in stats['par_subset'] else 0\n",
    "test_total = sum(stats['par_subset']['test'].values()) if 'test' in stats['par_subset'] else 0\n",
    "\n",
    "total_images = train_total + val_total + test_total\n",
    "\n",
    "if total_images > 0:\n",
    "    train_pct = (train_total / total_images) * 100\n",
    "    val_pct = (val_total / total_images) * 100\n",
    "    test_pct = (test_total / total_images) * 100\n",
    "    \n",
    "    print(f\"   R√©partition actuelle :\")\n",
    "    print(f\"   ‚Ä¢ Train : {train_total:,} ({train_pct:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Validation : {val_total:,} ({val_pct:.1f}%)\")\n",
    "    print(f\"   ‚Ä¢ Test : {test_total:,} ({test_pct:.1f}%)\")\n",
    "    \n",
    "    if val_pct < 10:\n",
    "        print(\"   ‚ö†Ô∏è ATTENTION : Ensemble de validation tr√®s petit !\")\n",
    "        print(\"   Recommandation : Redistribuer les donn√©es (70/15/15)\")\n",
    "    \n",
    "    if test_pct < 10:\n",
    "        print(\"   ‚ö†Ô∏è ATTENTION : Ensemble de test petit !\")\n",
    "        print(\"   Recommandation : Augmenter la taille du test set\")\n",
    "\n",
    "print(\"\\nüéØ OBJECTIFS DE PERFORMANCE\")\n",
    "print(\"   Pour un mod√®le de d√©tection de pneumonie :\")\n",
    "print(\"   ‚Ä¢ Sensibilit√© cible : > 90% (d√©tecter la pneumonie)\")\n",
    "print(\"   ‚Ä¢ Sp√©cificit√© cible : > 85% (√©viter faux positifs)\")\n",
    "print(\"   ‚Ä¢ F1-Score cible : > 0.87\")\n",
    "print(\"   ‚Ä¢ AUC-ROC cible : > 0.90\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "### R√©sum√© de l'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©ration du r√©sum√© final\n",
    "print(\"üìã R√âSUM√â DE L'ANALYSE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"üîç DATASET ANALYS√â :\")\n",
    "print(f\"   ‚Ä¢ Source : Kaggle - Paul Mooney\")\n",
    "print(f\"   ‚Ä¢ Total d'images : {stats['total_images']:,}\")\n",
    "print(f\"   ‚Ä¢ Classes : {', '.join(CLASSES)}\")\n",
    "print(f\"   ‚Ä¢ Sous-ensembles : {', '.join(SUBSETS)}\")\n",
    "\n",
    "print(\"‚öñÔ∏è D√âS√âQUILIBRE DES CLASSES :\")\n",
    "print(f\"   ‚Ä¢ Ratio : {ratio_desequilibre:.2f}:1\")\n",
    "print(f\"   ‚Ä¢ Classe majoritaire : {max(total_par_classe, key=total_par_classe.get)}\")\n",
    "print(f\"   ‚Ä¢ Classe minoritaire : {min(total_par_classe, key=total_par_classe.get)}\")\n",
    "\n",
    "print(\"üñºÔ∏è PROPRI√âT√âS DES IMAGES :\")\n",
    "print(f\"   ‚Ä¢ Dimensions moyennes : {proprietes['largeur_moyenne']:.0f}x{proprietes['hauteur_moyenne']:.0f}px\")\n",
    "print(f\"   ‚Ä¢ Taille moyenne : {proprietes['taille_moyenne_mb']:.2f} MB\")\n",
    "print(f\"   ‚Ä¢ Format principal : {max(proprietes['formats'], key=proprietes['formats'].get)}\")\n",
    "\n",
    "print(\"üö® PROBL√àMES IDENTIFI√âS :\")\n",
    "if val_pct < 10:\n",
    "    print(\"   ‚Ä¢ Ensemble de validation tr√®s petit\")\n",
    "if ratio_desequilibre > 2.0:\n",
    "    print(\"   ‚Ä¢ D√©s√©quilibre significatif des classes\")\n",
    "if len(set(proprietes['dimensions'])) > 10:\n",
    "    print(\"   ‚Ä¢ Dimensions d'images variables\")\n",
    "\n",
    "print(\"‚úÖ RECOMMANDATIONS CL√âS :\")\n",
    "print(\"   ‚Ä¢ Utiliser Transfer Learning (ResNet50/EfficientNet)\")\n",
    "print(\"   ‚Ä¢ Appliquer les poids de classes calcul√©s\")\n",
    "print(\"   ‚Ä¢ Augmentation de donn√©es cibl√©e\")\n",
    "print(\"   ‚Ä¢ M√©triques m√©dicales (Sensibilit√©, Sp√©cificit√©)\")\n",
    "print(\"   ‚Ä¢ Redistribution train/val/test si n√©cessaire\")\n",
    "\n",
    "print(\"üéØ PROCHAINES √âTAPES :\")\n",
    "print(\"   1. Preprocessing et normalisation des images\")\n",
    "print(\"   2. Impl√©mentation du mod√®le avec Transfer Learning\")\n",
    "print(\"   3. Entra√Ænement avec validation crois√©e\")\n",
    "print(\"   4. √âvaluation avec m√©triques m√©dicales\")\n",
    "print(\"   5. Optimisation et d√©ploiement\")\n",
    "\n",
    "print(\"\\nüéâ Analyse termin√©e avec succ√®s !\")\n",
    "print(\"üìä Rapport d√©taill√© sauvegard√© dans outputs/\")\n",
    "print(\"üìà Visualisations g√©n√©r√©es et affich√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde du rapport d'analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde du rapport complet\n",
    "print(\"üíæ Sauvegarde du rapport d'analyse...\")\n",
    "\n",
    "# Cr√©ation du rapport complet\n",
    "rapport_complet = {\n",
    "    'metadata': {\n",
    "        'dataset_source': 'Kaggle - Paul Mooney',\n",
    "        'dataset_url': 'https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia',\n",
    "        'analyse_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'auteur': 'Dady Akrou Cyrille'\n",
    "    },\n",
    "    'statistiques_dataset': stats,\n",
    "    'proprietes_images': proprietes,\n",
    "    'poids_classes': poids_classes,\n",
    "    'analyse_desequilibre': {\n",
    "        'ratio': ratio_desequilibre,\n",
    "        'classe_majoritaire': max(total_par_classe, key=total_par_classe.get),\n",
    "        'classe_minoritaire': min(total_par_classe, key=total_par_classe.get)\n",
    "    },\n",
    "    'recommandations': {\n",
    "        'architecture': 'Transfer Learning avec ResNet50/EfficientNet',\n",
    "        'gestion_desequilibre': 'Poids de classes + SMOTE',\n",
    "        'metriques': ['Sensibilit√©', 'Sp√©cificit√©', 'F1-Score', 'AUC-ROC'],\n",
    "        'augmentation_donnees': ['Rotation', 'Translation', 'Zoom', 'Contraste']\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sauvegarde en JSON\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "with open('outputs/rapport_analyse_notebook.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(rapport_complet, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Rapport sauvegard√© : outputs/rapport_analyse_notebook.json\")\n",
    "print(\"\\nüéØ Analyse compl√®te termin√©e !\")\n",
    "print(\"üìö Ce notebook peut √™tre utilis√© comme r√©f√©rence pour le d√©veloppement du mod√®le.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö R√©f√©rences et Cr√©dits\n",
    "\n",
    "- **Dataset :** [Chest X-Ray Images (Pneumonia)](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)\n",
    "- **Cr√©ateur du dataset :** Paul Mooney\n",
    "- **Plateforme :** Kaggle\n",
    "- **Auteur de l'analyse :** Dady Akrou Cyrille\n",
    "- **Date :** 2024\n",
    "\n",
    "---\n",
    "\n",
    "*Ce notebook pr√©sente une analyse compl√®te du dataset de radiographies thoraciques pour la d√©tection de pneumonie. Toutes les visualisations et recommandations sont bas√©es sur l'analyse statistique des donn√©es.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}